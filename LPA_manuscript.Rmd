---
title: "LPA Analysis"
output: html_notebook
---

Data analysis code for the latent profile analysis and the subsequent performance based clusters and figures reported in the manuscript. Figure 5 and 6.  

```{r}
library(mice)
library(dplyr)
library(pROC)
library(caret)
library(mice)
library(ggplot2)
library(mclust)
library(ggridges)
library(patchwork)
library(lavaan)
```


```{r}
# Read df with all the data 
df_risk <- read.csv("df_risk_deidetified.csv")
```

Imoutations 

```{r}
set.seed(8765)
# Function to calculate risk based on 20th percentile
calculate_risk <- function(df, outcome_column) {
  percentile_20 <- quantile(df[[outcome_column]], probs = 0.20, na.rm = TRUE)
  df %>% mutate(risk = ifelse(!!sym(outcome_column) <= percentile_20, 1, 0))
}
# Imputations
impute_data <- function(df, columns) {
  df_subset <- df %>% dplyr::select(all_of(c("student_tracking_id", columns)))
  imp <- mice(df_subset, print = FALSE, seed = 22112)
  as.data.frame(mice::complete(imp, 1))
}

process_grade <- function(df) {
  readOuts <- c("RO_T0", "RO_T1","RC_T1")
  wcj_2023 <- c("wcj_lwi_ss_2023","wcj_wa_ss_2023", "wcj_pc_2023", "wcj_srf_2023", "wcj_orf_2023")    
  wcj_2024 <- c("wcj_lwi_ss_2024","wcj_wa_ss_2024", "wcj_pc_ss_2024", "wcj_srf_ss_2024", "wcj_orf_ss_2024", "wcj_spelling_ss_2024")    
  wcj_2023_raw <- c("wcj_lwi_2023","wcj_wa_2023", "wcj_pc_2023", "wcj_srf_2023", "wcj_orf_2023")    
  wcj_2024_raw <- c("wcj_lwi_2024","wcj_wa_2024")    
  ngs_cols <- c("del_ucat_T0", "ble_ucat_T0", 
                 "evo_ucat_T0", 
                 "nwr_ucat_T0", "srt_ucat_T0",
                 "lsi_ucat_T0", 
                 "dgs_T0", 
                 "rao_T0",
                 "lco_T0",
                 "lnc_T0")
 
  vis_cols <- c("RVP_LT0", "RVP_PT0")
  motionCol <- c("GMC_T0")
  
  df_readOuts_imputed <- impute_data(df, readOuts)
  df_wcj_2023_imputed <- impute_data(df, wcj_2023)
  df_wcj_2024_imputed <- impute_data(df, wcj_2024)
  df_wcj_2023Raw_imputed <- impute_data(df, wcj_2023_raw)
  df_wcj_2024Raw_imputed <- impute_data(df, wcj_2024_raw)
  df_ngs_imputed <- impute_data(df, ngs_cols)
  df_vis_imputed <- impute_data(df, vis_cols)
  df_motion_imputed <- impute_data(df, motionCol)
  
  Reduce(function(x, y) merge(x, y, by = "student_tracking_id"), 
         list( df_wcj_2023_imputed, df_wcj_2024_imputed, df_readOuts_imputed,
              df_wcj_2023Raw_imputed, df_wcj_2024Raw_imputed, 
              df_ngs_imputed, df_vis_imputed,df_motion_imputed))
}


df_risk_K <- df_risk %>% filter( grade_2023 ==0 )
df_risk_1 <- df_risk %>% filter( grade_2023 ==1 )
df_risk_2 <- df_risk %>% filter( grade_2023 ==2 )
#
imputed_K <- process_grade(df_risk_K)
imputed_1 <- process_grade(df_risk_1)

# Combine the imputed data frames
df_imputed <- rbind(imputed_K, imputed_1)

df_demo <- df_risk %>% dplyr::select(student_tracking_id, grade_2023, ELstatus,risk,riskSY, frpm_eligibility,wcj_c_basicreadingskills_2024,wcj_c_boardreading_2024, wcj_c_reading_2024,wcj_c_readingfluency_2024)

df_risk_imputed <- left_join(df_imputed, df_demo, by = "student_tracking_id")

# Calculate EL status
df_ELdemo <- read.csv('~/Library/CloudStorage/GoogleDrive-maha10@stanford.edu/My Drive/Longitudinal-DataAnalysis-Multitudes2024/allStudents_ELStatus.csv')

df_risk_imputed <- left_join(df_risk_imputed, df_ELdemo, by = "student_tracking_id")

df_risk_imputed <- df_risk_imputed %>% mutate(ELStatus = case_when(rptglng =="Spanish" ~ "EL", 
                                                   rptglng =="English" ~ "EO")) 

```

Select respective columns for each grade 

```{r}
colsList_coh2_K <- c("student_tracking_id","RVP_LT0","RVP_PT0", "del_ucat_T0", "ble_ucat_T0", "nwr_ucat_T0", "srt_ucat_T0", "dgs_T0", "rao_T0","grade_2023", "ELStatus", "risk","RO_T0","RO_T1","GMC_T0", "frpm_eligibility", "wcj_lwi_ss_2024", "wcj_wa_ss_2024", "wcj_pc_ss_2024", "wcj_srf_ss_2024","wcj_lwi_ss_2023","wcj_lwi_2023","wcj_lwi_2024","wcj_wa_2023", "wcj_wa_2024", "wcj_wa_ss_2023","wcj_c_basicreadingskills_2024","wcj_c_boardreading_2024","wcj_c_readingfluency_2024","wcj_c_reading_2024")
colsList_coh2_1 <- c("student_tracking_id","RVP_LT0","RVP_PT0", "del_ucat_T0", "evo_ucat_T0", "nwr_ucat_T0", "srt_ucat_T0", "dgs_T0", "rao_T0","grade_2023", "ELStatus", "risk","RO_T0","RO_T1","GMC_T0", "frpm_eligibility","wcj_lwi_ss_2024", "wcj_wa_ss_2024", "wcj_pc_ss_2024", "wcj_srf_ss_2024","wcj_lwi_ss_2023","wcj_lwi_2023","wcj_lwi_2024","wcj_wa_2023", "wcj_wa_2024", "wcj_wa_ss_2023","wcj_c_basicreadingskills_2024","wcj_c_boardreading_2024","wcj_c_readingfluency_2024","wcj_c_reading_2024")

df_dum <- df_risk_imputed %>% dplyr::select(colsList_coh2_K)

df_subset <- df_risk_imputed[,colsList_coh2_K];
df_subset <- df_subset %>% filter( grade_2023 == 0)
columns_to_check <- c("RVP_LT0","RVP_PT0",  "del_ucat_T0", "ble_ucat_T0",
                      "nwr_ucat_T0", "dgs_T0", "rao_T0")

clean_data <- df_subset %>%
  filter(across(all_of(columns_to_check), ~ !is.na(.))) #%>% filter(ELStatus =="EL")

# Save original order of student IDs
original_ids <- clean_data$student_tracking_id

# Store the columns you want to add back
id_cols <- clean_data %>% 
  dplyr::select(student_tracking_id, grade_2023, ELStatus, risk, RO_T0, RO_T1, frpm_eligibility,wcj_lwi_2023,wcj_wa_2023, wcj_lwi_2024,wcj_wa_2024, 
                #wcj_pc_2023, wcj_srf_2023, wcj_lwi_2024, wcj_wa_2024, wcj_pc_2024, wcj_srf_2024,
                wcj_c_boardreading_2024,wcj_c_basicreadingskills_2024,wcj_c_reading_2024,wcj_c_readingfluency_2024, wcj_c_reading_2024,  wcj_lwi_ss_2023, wcj_lwi_ss_2024, wcj_wa_ss_2023, wcj_wa_ss_2024)

df_subset <- clean_data  %>% dplyr::select(-c(student_tracking_id,grade_2023, ELStatus, risk, frpm_eligibility,wcj_lwi_ss_2023, wcj_wa_ss_2023, wcj_lwi_ss_2024, wcj_wa_ss_2024, wcj_pc_ss_2024, wcj_srf_ss_2024, wcj_c_basicreadingskills_2024,wcj_c_boardreading_2024,wcj_c_reading_2024,wcj_c_readingfluency_2024, wcj_lwi_2023, wcj_lwi_2024, wcj_wa_2023, wcj_wa_2024)) 

# Z-score the predictors
df_subset <- as.data.frame(scale(df_subset))

# Verify order is maintained
scaled_with_ids <- bind_cols(id_cols, df_subset)

# Check if order matches
all(scaled_with_ids$student_tracking_id == original_ids)  # Should return TRUE

# If you want to be extra safe, you could use a join instead:
df_subset_safe <- id_cols %>%
  bind_cols(df_subset)
```

```{r}
df_subset <- df_subset %>% dplyr::select(-c(RO_T0, RO_T1))
```

Visualize the model and BIC criterion 
```{r}
# Fit the Latent Profile Analysis (Gaussian Mixture Model)
set.seed(234543)
lpa_model <- Mclust(df_subset)
# Summary of the model
summary(lpa_model)
plot(lpa_model, what='BIC', model ="EEI")
plot(lpa_model, what='classification', model ="EEI")
# Check the number of identified clusters
clusters <- lpa_model$classification
probs <- lpa_model$z
# Add cluster membership to the original data
df_with_clusters <- clean_data %>%
  mutate(Cluster = as.factor(clusters))
df_with_clusters_plot <- df_subset_safe %>%
  mutate(Cluster = as.factor(clusters))
```

```{r}
## Create Clusters based on KG classification and force assign students to these 
df_createClusters <- df_with_clusters_plot %>%
    mutate(PerfGroups = case_when(
      RVP_LT0 > 0.25 & RVP_PT0 > 0.25 &
            del_ucat_T0 <= -.01 ~ "Specific Visual Strength",
        RVP_LT0 < -0.250 & RVP_PT0 < -0.25 &
            del_ucat_T0 >= 0.1 ~ "Specific Visual Challenge",
        RVP_LT0 > 0.1 &
            del_ucat_T0 > 0.1 & srt_ucat_T0 > 0.01  ~ "High Performers",
        RVP_LT0 < -0  &
            del_ucat_T0 < -0.010 & srt_ucat_T0 < -0.01  ~ "Low Performers",
        TRUE ~ "Average Performers"
    ))
```

Figures 5 and 6
```{r}
# First calculate the counts
cluster_counts <- table(df_createClusters$PerfGroups)

# Compute mean for each PerfGroups
mean_values <- df_createClusters %>%
  group_by(PerfGroups) %>%
  summarise(mean_x = mean(wcj_lwi_ss_2024, na.rm = TRUE)) %>%
  arrange(mean_x)

# Reorder PerfGroups based on the computed mean
df_createClusters$PerfGroups <- factor(df_createClusters$PerfGroups, 
                                       levels = mean_values$PerfGroups)

# Plot with reordered x-axis
ggplot(df_createClusters, aes(y = PerfGroups, x = wcj_lwi_ss_2024, fill = PerfGroups)) +
  geom_boxplot() +
  geom_vline(xintercept = percentile_20, color = "gray", linetype = "dashed", size = 1) +
  scale_fill_brewer(palette = "Set2") +
  scale_fill_manual(values = c("chocolate3", "cornsilk4", "cornflowerblue","aquamarine3","darkslategray4"),
                    labels = paste0("Cluster ", names(cluster_counts), 
                                  " (n=", cluster_counts, ")"),
                    name = "Cluster") +
  theme_minimal() +
  labs(
    title = "",
    y ="",
    #x = "Clusters",
    x = "WCJ- LWI (a year later)",
    fill = "PerfGroups"
  ) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1, size = 10),
         axis.text.y = element_text(size = 10),
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
  )

```

## Profile plots - the task profiles 

```{r}
predictor_order <- c("evo_ucat_T0", "ble_ucat_T0", "del_ucat_T0", "srt_ucat_T0",  "nwr_ucat_T0","dgs_T0", "rao_T0","GMC_T0", "RVP_LT0", "RVP_PT0" )

cluster_means <- df_createClusters %>% #filter(PerfGroups == "Specific Visual Strength" | PerfGroups == "Specific Visual Challenge" ) %>% 
  #filter(PerfGroups == "High Performers" | PerfGroups == "Low Performers" | PerfGroups == "Average Performers") %>% 
  group_by(PerfGroups) %>%
  summarise(across(c(evo_ucat_T0,del_ucat_T0, dgs_T0, nwr_ucat_T0,rao_T0, RVP_LT0, RVP_PT0,GMC_T0, srt_ucat_T0), mean, na.rm = TRUE)) %>%
  tidyr::pivot_longer(-PerfGroups, names_to = "Predictor", values_to = "Mean")
# Create a named vector for label mapping
predictor_labels <- c(
  "evo_ucat_T0" = "Vocabulary", 
  "ble_ucat_T0" = "Blending",
  "del_ucat_T0" = "Deletion",
  "dgs_T0" = "Digit Span",
  "nwr_ucat_T0" = "Nonword Repetition",
  "rao_T0" = "RAN",
  "GMC_T0" = "Motion",
  "RVP_LT0" = "MEP-L",
  "RVP_PT0" = "MEP-P",
  "srt_ucat_T0" = "Sentence Repetition"
)

profile_plot <- ggplot(cluster_means, 
                        aes(x = factor(Predictor, levels = predictor_order), 
                            y = Mean, 
                            color = PerfGroups,
                            group = PerfGroups)) +
     # Add connecting lines between points
     geom_line(size = 1.2) +
     # Add points
     geom_point(size = 3) +
     # Add confidence intervals if desired
     # geom_errorbar(aes(ymin = Z_Score - se, ymax = Z_Score + se), width = 0.2) +
     # Customize colors
     scale_color_manual(values = c("chocolate3", "cornsilk4", "cornflowerblue","aquamarine3",  "darkslategray4"),labels = paste0("", names(cluster_counts), 
                                  " (n=", cluster_counts, ")"),
                    name = "Cluster") +
     #scale_color_manual(values = c("chocolate3", "cornsilk4",  "darkslategray4")) +
     #scale_color_manual(values = c("cornflowerblue","aquamarine3")) +
     # Rotate x-axis labels for better readability
     scale_x_discrete(labels = predictor_labels) +
     # Add reference line at zero
     geom_hline(yintercept = 0, linetype = "dashed", color = "gray50", alpha = 0.5) +
     # Customize theme
     theme_minimal() +
     theme(
         axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
         axis.text.y = element_text(size = 10),
         axis.title = element_text(size = 12),
         legend.title = element_text(size = 12),
         legend.text = element_text(size = 10),
         plot.title = element_text(size = 14, hjust = 0.5),
         plot.subtitle = element_text(size = 11, hjust = 0.5),
         panel.grid.minor = element_blank(),
         panel.grid.major.x = element_blank()
     ) +
     labs(
         title = "Cluster Profiles",
         subtitle = "",
         x = "Measures",
         y = "Scores",
         color = "PerfGroups"
     )
profile_plot

```

## Plot the trends line plots 

```{r}
plot_data <- df_createClusters %>% 
 tidyr::pivot_longer(
#    cols = c(RO_T0, RO_T1),
    cols = c(wcj_lwi_ss_2023, wcj_lwi_ss_2024),
    names_to = "time_point",
    values_to = "reading_outcome"
  ) %>%
  mutate(
    # Convert time points to factors with nice labels
    time_point = factor(time_point, 
                       levels = c("wcj_lwi_ss_2023", "wcj_lwi_ss_2024"),
                       labels = c("concurrent-year", "a year-later"))
  )


# Calculate mean trajectories for each cluster
mean_trajectories <- plot_data %>%
  group_by(PerfGroups, time_point) %>%
  summarize(mean_outcome = mean(reading_outcome, na.rm = TRUE))

# Create the plot with both individual and mean trajectories
ggplot() +
  geom_line(data = plot_data,
            aes(x = time_point, 
                y = reading_outcome, 
                group = student_tracking_id,
                color = (PerfGroups)),
                alpha = 0.2) +
  # Mean trajectories (thicker lines)
  geom_line(data = mean_trajectories,
            aes(x = time_point, 
                y = mean_outcome, 
                group = PerfGroups,
                color = (PerfGroups)),
            size = 2) +
  geom_point(data = mean_trajectories,
             aes(x = time_point, 
                 y = mean_outcome,
                 color = (PerfGroups)),
             size = 4) + #scale_y_continuous(50:150) +
   scale_color_manual(values = c("chocolate3", "cornflowerblue","aquamarine3","cornsilk4", "darkslategray4"),
                  name = "PerfGroups") +
  labs(
   # title = "Reading Outcomes Over Time by Cluster",
    subtitle = "",
    x = "",
    #y = "WCJ LWI (raw scores)"
    y = "WCJ-LWI "
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, size = 12),
         axis.text.y = element_text(size = 12),
    legend.position = "right",
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

library(emmeans)
df_growth <- plot_data %>% pivot_wider(names_from = time_point,
  values_from = reading_outcome)

library(lme4)
library(lmerTest)
model <- lmer(reading_outcome ~ time_point * PerfGroups + (1 | student_tracking_id), data = plot_data)

summary(model)
anova(model)
pairs(emmeans(model, ~ time_point | PerfGroups))

plot_data <- df_createClusters %>% 
  tidyr::pivot_longer(
#    cols = c(RO_T0, RO_T1),
    cols = c(wcj_wa_ss_2023, wcj_wa_ss_2024),
    names_to = "time_point",
    values_to = "reading_outcome"
  ) %>%
  mutate(
    # Convert time points to factors with nice labels
    time_point = factor(time_point, 
                       levels = c("wcj_wa_ss_2023", "wcj_wa_ss_2024"),
                       labels = c("concurrent-year", "a year-later"))
  )

# Calculate mean trajectories for each cluster
mean_trajectories <- plot_data %>%
  group_by(PerfGroups, time_point) %>%
  summarize(mean_outcome = mean(reading_outcome, na.rm = TRUE))

# Create the plot with both individual and mean trajectories
ggplot() +
  # Individual trajectories (more transparent)
  geom_line(data = plot_data,
            aes(x = time_point, 
                y = reading_outcome, 
                group = student_tracking_id,
                color = factor(PerfGroups)),
            alpha = 0.2) +
  # Mean trajectories (thicker lines)
  geom_line(data = mean_trajectories,
            aes(x = time_point, 
                y = mean_outcome, 
                group = PerfGroups,
                color = (PerfGroups)),
            size = 2) +
  geom_point(data = mean_trajectories,
             aes(x = time_point, 
                 y = mean_outcome,
                 color = factor(PerfGroups)),
             size = 4) + #scale_y_continuous(50:150) +
   scale_color_manual(values = c("chocolate3","cornsilk4", "cornflowerblue","aquamarine3",  "darkslategray4"),
                  # labels = legend_labels,
                  name = "Cluster") +
  labs(
   # title = "Reading Outcomes Over Time by Cluster",
    subtitle = "",
    x = "",
    #y = "WCJ Word attack (raw scores)"
    y = "WCJ Word attack (age standardized scores)"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )


```

## Distribution of reading outcomes 

```{r}

df_createClusters <- df_createClusters %>% mutate(readingGrowth_LWI = wcj_lwi_2024 - wcj_lwi_2023) %>% mutate(readingGrowth_WA = wcj_wa_2024 - wcj_wa_2023) 
# Correct color mapping to match the line plot
cluster_colors <- c(
 "#D55E00",      # Orange/brown
 "#999999", 
 "#56B4E9",  # Light blue
 "#009E73",    # Turquoise
         # Grey
 "#006666"            # Dark teal
)

create_half_violin <- function(data, column, x_label) {
  # Calculate medians for each cluster
  medians <- data %>%
    group_by(PerfGroups) %>%
    summarise(median = median(.data[[column]], na.rm = TRUE)) %>%
    arrange(desc(median))  # Sort by median for ordering
  
  # Set factor levels based on ordered medians
  data$Cluster <- factor(data$PerfGroups, 
                        levels = medians$PerfGroups)
  
  # Calculate global min and max for x-axis
  global_min <- floor(min(data[[column]], na.rm = TRUE) / 20) * 20
  global_max <- ceiling(max(data[[column]], na.rm = TRUE) / 20) * 20
  
  ggplot(data, aes(x = .data[[column]], y = (PerfGroups), fill = (PerfGroups))) +
    geom_density_ridges(
      scale = 2,            
      rel_min_height = 0.01,
      alpha = 0.8,          
      color = "black",      
      size = 0.5           
    ) +
    # Add median lines with matching colors
    geom_segment(
      data = medians,
      aes(
        x = median,
        xend = median,
        y = as.numeric((PerfGroups)) - 0.1,
        yend = as.numeric((PerfGroups)) + 0.1,
        color = (PerfGroups)  # Use color aesthetic for median lines
      ),
     # linetype = "dotted",
      size = 2,
      inherit.aes = FALSE
    ) +
    scale_fill_manual(values = cluster_colors) +
    scale_color_manual(values = cluster_colors) +  # Add color scale for median lines
    scale_x_continuous(
      limits = c(global_min, global_max),
      breaks = seq(global_min, global_max, by = 20),
      minor_breaks = seq(global_min, global_max, by = 20)
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_blank(),    
      axis.title.y = element_blank(),   
      axis.title.x = element_text(size = 15, face = "bold"),
      axis.text.x = element_text(size = 15),
      panel.grid.major.y = element_blank(),
      panel.grid.minor = element_blank(),
      legend.position = "right",
      plot.title = element_blank()
    ) +
    xlab(x_label)
}

# Rest of your original code remains the same
metrics <- c(
  #"wcj_lwi_2023" = "WCJ-LWI-T0",
  #"wcj_lwi_2024" = "WCJ-LWI-T1",
  #"wcj_wa_2023" = "WCJ-WA-T0",
  #"wcj_wa_2024" = "WCJ-WA-T1",
# "readingGrowth_LWI" = "LWI Growth"
# "readingGrowth_WA" = "WA Growth"
  "wcj_c_basicreadingskills_2024" = "Basic Reading Skills",
  "wcj_c_boardreading_2024" = "Broad Reading",
  "wcj_c_readingfluency_2024" = "Reading Fluency",
  "wcj_c_reading_2024" = "Reading Score"
)

# Calculate global min and max across all metrics
global_min <- global_max <- NULL
for(metric in names(metrics)) {
  curr_min <- floor(min(df_createClusters[[metric]], na.rm = TRUE) / 20) * 20
  curr_max <- ceiling(max(df_createClusters[[metric]], na.rm = TRUE) / 20) * 20
  global_min <- min(global_min, curr_min, na.rm = TRUE)
  global_max <- max(global_max, curr_max, na.rm = TRUE)
}

plots <- list()
for(metric in names(metrics)) {
  plots[[metric]] <- create_half_violin(df_createClusters, metric, metrics[[metric]])
}
```


```{r}
risk_percentages <- df_createClusters %>%
  group_by(PerfGroups) %>%
  summarise(
    percent_at_risk = mean(risk == 1, na.rm = TRUE) * 100,
    .groups = "drop"
  ) %>%
  mutate(Cluster = factor(PerfGroups))

# Create the plot
p1 <- ggplot(risk_percentages, aes(x = PerfGroups, y = percent_at_risk)) +
  geom_col(fill = "#e06666") +
  geom_text(aes(label = sprintf("%.1f%%", percent_at_risk)),
            vjust = -0.5) +
  labs(title = "Percentage of Students At-Risk by Cluster",
       subtitle = "Risk is scores below 20th percentile in WCJ-BRS for each grade",
       x = "Cluster",
       y = "Percentage At Risk") +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    panel.grid.major.x = element_blank()
  ) +
  scale_y_continuous(
    limits = c(0, max(risk_percentages$percent_at_risk) * 1.1),
    labels = function(x) paste0(x, "%")
  )
p1
```


